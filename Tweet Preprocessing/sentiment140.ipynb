{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44b97e5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-24T19:12:33.293109Z",
     "iopub.status.busy": "2021-12-24T19:12:33.292492Z",
     "iopub.status.idle": "2021-12-24T19:12:33.302459Z",
     "shell.execute_reply": "2021-12-24T19:12:33.302853Z",
     "shell.execute_reply.started": "2021-12-24T18:07:59.608686Z"
    },
    "papermill": {
     "duration": 0.032541,
     "end_time": "2021-12-24T19:12:33.303174",
     "exception": false,
     "start_time": "2021-12-24T19:12:33.270633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9743c6e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:12:33.332375Z",
     "iopub.status.busy": "2021-12-24T19:12:33.331711Z",
     "iopub.status.idle": "2021-12-24T19:12:39.438537Z",
     "shell.execute_reply": "2021-12-24T19:12:39.438078Z",
     "shell.execute_reply.started": "2021-12-24T18:07:59.724269Z"
    },
    "papermill": {
     "duration": 6.122434,
     "end_time": "2021-12-24T19:12:39.438666",
     "exception": false,
     "start_time": "2021-12-24T19:12:33.316232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score          id                      datetime      flag  \\\n",
       "0            0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1            0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2            0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3            0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4            0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "...        ...         ...                           ...       ...   \n",
       "1599994      4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599995      4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996      4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997      4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998      4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4               joy_wolf                      @Kwesidei not the whole crew   \n",
       "...                  ...                                                ...  \n",
       "1599994  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599995      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599996           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599997     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599998   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1599999 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/sentiment140/training.1600000.processed.noemoticon.csv\",encoding='latin-1')\n",
    "df.columns=['score','id','datetime','flag','user','text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c7298f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:12:39.464348Z",
     "iopub.status.busy": "2021-12-24T19:12:39.463808Z",
     "iopub.status.idle": "2021-12-24T19:12:53.394883Z",
     "shell.execute_reply": "2021-12-24T19:12:53.394332Z",
     "shell.execute_reply.started": "2021-12-24T18:08:07.638877Z"
    },
    "papermill": {
     "duration": 13.944789,
     "end_time": "2021-12-24T19:12:53.395023",
     "exception": false,
     "start_time": "2021-12-24T19:12:39.450234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ekphrasis\r\n",
      "  Downloading ekphrasis-0.5.1.tar.gz (80 kB)\r\n",
      "     |████████████████████████████████| 80 kB 341 kB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (1.1.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (4.62.3)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (0.4.4)\r\n",
      "Requirement already satisfied: ujson in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (4.2.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (3.5.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (3.2.4)\r\n",
      "Collecting ftfy\r\n",
      "  Downloading ftfy-6.0.3.tar.gz (64 kB)\r\n",
      "     |████████████████████████████████| 64 kB 869 kB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (1.19.5)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from ftfy->ekphrasis) (0.2.5)\r\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (6.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (0.11.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (1.3.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (2.8.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (3.0.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (21.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (8.2.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (4.28.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->ekphrasis) (1.16.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib->ekphrasis) (59.1.1)\r\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib->ekphrasis) (1.2.2)\r\n",
      "Building wheels for collected packages: ekphrasis, ftfy\r\n",
      "  Building wheel for ekphrasis (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=82842 sha256=4324dabbd9b108184f3b1ea2f318dcbd7bda001b125292f54d014c70f1d4a2e1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/f7/ec/0d/12659e32faf780546945d0120f2c8410eb3efb7426731da88f\r\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=4933652f18f4c863a7736085d3e443c5565ad057d6941769f6fd0b7ff62cc9bf\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\r\n",
      "Successfully built ekphrasis ftfy\r\n",
      "Installing collected packages: ftfy, ekphrasis\r\n",
      "Successfully installed ekphrasis-0.5.1 ftfy-6.0.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ekphrasis\n",
    "from ekphrasis.classes.segmenter import Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ea1a5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:12:53.435119Z",
     "iopub.status.busy": "2021-12-24T19:12:53.432511Z",
     "iopub.status.idle": "2021-12-24T19:12:55.278897Z",
     "shell.execute_reply": "2021-12-24T19:12:55.278419Z",
     "shell.execute_reply.started": "2021-12-24T18:08:24.423046Z"
    },
    "papermill": {
     "duration": 1.866438,
     "end_time": "2021-12-24T19:12:55.279025",
     "exception": false,
     "start_time": "2021-12-24T19:12:53.412587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "#important libraries for preprocessing using NLTK\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e4c616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:12:55.320177Z",
     "iopub.status.busy": "2021-12-24T19:12:55.319560Z",
     "iopub.status.idle": "2021-12-24T19:12:55.745453Z",
     "shell.execute_reply": "2021-12-24T19:12:55.745857Z",
     "shell.execute_reply.started": "2021-12-24T18:08:26.331690Z"
    },
    "papermill": {
     "duration": 0.449641,
     "end_time": "2021-12-24T19:12:55.746016",
     "exception": false,
     "start_time": "2021-12-24T19:12:55.296375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score       0\n",
       "id          0\n",
       "datetime    0\n",
       "flag        0\n",
       "user        0\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f7dc5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:12:55.790605Z",
     "iopub.status.busy": "2021-12-24T19:12:55.789478Z",
     "iopub.status.idle": "2021-12-24T19:13:02.114415Z",
     "shell.execute_reply": "2021-12-24T19:13:02.114867Z",
     "shell.execute_reply.started": "2021-12-24T18:08:27.198713Z"
    },
    "papermill": {
     "duration": 6.351667,
     "end_time": "2021-12-24T19:13:02.115042",
     "exception": false,
     "start_time": "2021-12-24T19:12:55.763375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['hashtag']=df['text'].apply(lambda x:re.findall(r\"#(\\w+)\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ac28e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:13:02.312130Z",
     "iopub.status.busy": "2021-12-24T19:13:02.153252Z",
     "iopub.status.idle": "2021-12-24T19:13:02.612574Z",
     "shell.execute_reply": "2021-12-24T19:13:02.612034Z",
     "shell.execute_reply.started": "2021-12-24T18:08:37.682016Z"
    },
    "papermill": {
     "duration": 0.47978,
     "end_time": "2021-12-24T19:13:02.612705",
     "exception": false,
     "start_time": "2021-12-24T19:13:02.132925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "      <td>[charitytuesday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text           hashtag\n",
       "0        is upset that he can't update his Facebook by ...                []\n",
       "1        @Kenichan I dived many times for the ball. Man...                []\n",
       "2          my whole body feels itchy and like its on fire                 []\n",
       "3        @nationwideclass no, it's not behaving at all....                []\n",
       "4                            @Kwesidei not the whole crew                 []\n",
       "...                                                    ...               ...\n",
       "1599994  Just woke up. Having no school is the best fee...                []\n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...                []\n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...                []\n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...                []\n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...  [charitytuesday]\n",
       "\n",
       "[1599999 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(df.columns[[0, 1, 2, 3, 4]], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4fbd44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:13:02.653766Z",
     "iopub.status.busy": "2021-12-24T19:13:02.653176Z",
     "iopub.status.idle": "2021-12-24T19:38:16.030177Z",
     "shell.execute_reply": "2021-12-24T19:38:16.029188Z",
     "shell.execute_reply.started": "2021-12-24T18:10:02.927522Z"
    },
    "papermill": {
     "duration": 1513.4,
     "end_time": "2021-12-24T19:38:16.030562",
     "exception": false,
     "start_time": "2021-12-24T19:13:02.630562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word statistics files not found!\n",
      "Downloading... done!\n",
      "Unpacking... done!\n",
      "Reading twitter - 1grams ...\n",
      "generating cache file for faster loading...\n",
      "reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n",
      "Reading twitter - 2grams ...\n",
      "generating cache file for faster loading...\n",
      "reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "# segmenter using the word statistics from Twitter\n",
    "seg_tw = Segmenter(corpus=\"twitter\")\n",
    "a = []\n",
    "for i in range(len(df)):\n",
    " if df['hashtag'][i] != a:\n",
    "  listToStr1 = ' '.join([str(elem) for elem in df['hashtag'][i]])\n",
    "  df.loc[i,'Segmented#'] = seg_tw.segment(listToStr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c03886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:38:16.134992Z",
     "iopub.status.busy": "2021-12-24T19:38:16.133556Z",
     "iopub.status.idle": "2021-12-24T19:38:16.800412Z",
     "shell.execute_reply": "2021-12-24T19:38:16.799762Z",
     "shell.execute_reply.started": "2021-12-24T18:58:36.494089Z"
    },
    "papermill": {
     "duration": 0.747843,
     "end_time": "2021-12-24T19:38:16.800567",
     "exception": false,
     "start_time": "2021-12-24T19:38:16.052724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "0        is upset that he can't update his Facebook by ...\n",
       "1        @Kenichan I dived many times for the ball. Man...\n",
       "2          my whole body feels itchy and like its on fire \n",
       "3        @nationwideclass no, it's not behaving at all....\n",
       "4                            @Kwesidei not the whole crew \n",
       "...                                                    ...\n",
       "1599994  Just woke up. Having no school is the best fee...\n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1599999 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Segmented#']=df['Segmented#'].fillna('')\n",
    "df['text']=df['text'].astype(str)+df['Segmented#']\n",
    "df=df.drop(df.columns[[1, 2]], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20fac9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:38:16.897615Z",
     "iopub.status.busy": "2021-12-24T19:38:16.896927Z",
     "iopub.status.idle": "2021-12-24T19:38:16.900116Z",
     "shell.execute_reply": "2021-12-24T19:38:16.899611Z",
     "shell.execute_reply.started": "2021-12-24T18:48:03.774086Z"
    },
    "papermill": {
     "duration": 0.079014,
     "end_time": "2021-12-24T19:38:16.900248",
     "exception": false,
     "start_time": "2021-12-24T19:38:16.821234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    " #Removes Numbers\n",
    " data = data.astype(str).str.replace('\\d+', '')\n",
    " lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    " w_tokenizer =  TweetTokenizer()\n",
    " stop_words = set(stopwords.words('english'))\n",
    " def lemmatize_text(text):\n",
    "  return [(lemmatizer.lemmatize(w)) for w in w_tokenizer.tokenize((text))]\n",
    " def remove_punctuation(words):\n",
    "  new_words = []\n",
    "  finalwords = []\n",
    "  for word in words:\n",
    "      new_word = re.sub(r'[^\\w\\s]', '', (word))\n",
    "      if new_word!='':\n",
    "         new_words.append(new_word)\n",
    "  for word in new_words:\n",
    "    if len(word)>2:\n",
    "        finalwords.append(word)\n",
    "  return finalwords\n",
    " words = data.apply(lemmatize_text)\n",
    " words = words.apply(remove_punctuation)\n",
    " words = words.apply(lambda x: [item for item in x if item not in stop_words])\n",
    " return pd.DataFrame(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167dad01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:38:16.944252Z",
     "iopub.status.busy": "2021-12-24T19:38:16.942835Z",
     "iopub.status.idle": "2021-12-24T19:38:17.012151Z",
     "shell.execute_reply": "2021-12-24T19:38:17.011611Z",
     "shell.execute_reply.started": "2021-12-24T18:59:16.759130Z"
    },
    "papermill": {
     "duration": 0.091601,
     "end_time": "2021-12-24T19:38:17.012292",
     "exception": false,
     "start_time": "2021-12-24T19:38:16.920691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>@KimokoMasada I wished I could tell you to sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>in London at the mo. It's ridiculously hot and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>Just one more day in San Jose and then we're o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>@WerewolfEmbry She *is* kind of right though E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0       is upset that he can't update his Facebook by ...\n",
       "1       @Kenichan I dived many times for the ball. Man...\n",
       "2         my whole body feels itchy and like its on fire \n",
       "3       @nationwideclass no, it's not behaving at all....\n",
       "4                           @Kwesidei not the whole crew \n",
       "...                                                   ...\n",
       "159995  @KimokoMasada I wished I could tell you to sto...\n",
       "159996  in London at the mo. It's ridiculously hot and...\n",
       "159997  Just one more day in San Jose and then we're o...\n",
       "159998  @WerewolfEmbry She *is* kind of right though E...\n",
       "159999  @tiffanylue i know  i was listenin to bad habi...\n",
       "\n",
       "[160000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew=np.array_split(df, 10)\n",
    "dfnew[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d97ae10b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:38:17.061443Z",
     "iopub.status.busy": "2021-12-24T19:38:17.060383Z",
     "iopub.status.idle": "2021-12-24T19:38:32.506310Z",
     "shell.execute_reply": "2021-12-24T19:38:32.505775Z",
     "shell.execute_reply.started": "2021-12-24T18:59:20.526122Z"
    },
    "papermill": {
     "duration": 15.473914,
     "end_time": "2021-12-24T19:38:32.506470",
     "exception": false,
     "start_time": "2021-12-24T19:38:17.032556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "for i in range(10):\n",
    "    dfnew[i]['text']=dfnew[i]['text'].apply(lambda x:re.sub(r'@\\w+', '', x).strip())\n",
    "    dfnew[i]['text']=dfnew[i]['text'].apply(lambda x: emoji_pattern.sub(r'', x).lower())\n",
    "    dfnew[i]['text']=dfnew[i]['text'].apply(lambda x:re.sub(r'#\\w+', '', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d33a669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:38:32.549945Z",
     "iopub.status.busy": "2021-12-24T19:38:32.549062Z",
     "iopub.status.idle": "2021-12-24T19:38:32.571436Z",
     "shell.execute_reply": "2021-12-24T19:38:32.571870Z",
     "shell.execute_reply.started": "2021-12-24T18:59:43.640901Z"
    },
    "papermill": {
     "duration": 0.045502,
     "end_time": "2021-12-24T19:38:32.572026",
     "exception": false,
     "start_time": "2021-12-24T19:38:32.526524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                     text\n",
       " 0       is upset that he can't update his facebook by ...\n",
       " 1       i dived many times for the ball. managed to sa...\n",
       " 2          my whole body feels itchy and like its on fire\n",
       " 3       no, it's not behaving at all. i'm mad. why am ...\n",
       " 4                                      not the whole crew\n",
       " ...                                                   ...\n",
       " 159995  i wished i could tell you to stop tweeting 'ca...\n",
       " 159996  in london at the mo. it's ridiculously hot and...\n",
       " 159997  just one more day in san jose and then we're o...\n",
       " 159998  she *is* kind of right though embers...sometim...\n",
       " 159999  i know  i was listenin to bad habit earlier an...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 160000  layin n bed with a headache  ughhhh...waitin o...\n",
       " 160001                funeral ceremony...gloomy friday...\n",
       " 160002               wants to hang out with friends soon!\n",
       " 160003  we want to trade with someone who has houston ...\n",
       " 160004  re-pinging : why didn't you go to prom? bc my ...\n",
       " ...                                                   ...\n",
       " 319995  kinda like that for me too  i like my straight...\n",
       " 319996  well, i'm watching the tv at this moment ;) bu...\n",
       " 319997  finally get to use internet after 5 days. inte...\n",
       " 319998  we just talked to fedex. looks like the slurpe...\n",
       " 319999                 morning!!!!! i finally made it in!\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 320000  no one ever gave jake any credit when they rea...\n",
       " 320001  great, got a virus just wot i need in the midd...\n",
       " 320002  moving some of the data to dvd's.. have no mor...\n",
       " 320003  you will be missed, ian.  take care, and best ...\n",
       " 320004  my fb account is cluttered by so much useless ...\n",
       " ...                                                   ...\n",
       " 479995  aww  i always hated going to the dentist. i ho...\n",
       " 479996                      goood morning! math exam soon\n",
       " 479997  poor little boy is still sick  still a pretty ...\n",
       " 479998  you just lost seven points for that comment! i...\n",
       " 479999  still trying for that iphone from ... forgot a...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 480000               i'm studying greek history!! help me\n",
       " 480001  gauging from the wait at security at san diego...\n",
       " 480002                                     sucked at golf\n",
       " 480003  finished my jobs for the day &amp; typically t...\n",
       " 480004  &quot;good....morning.......bayside,........&q...\n",
       " ...                                                   ...\n",
       " 639995  i need to go out tonight..i need to unwind..bu...\n",
       " 639996                      internet not workin. again...\n",
       " 639997             is now thinking too much.. can't sleep\n",
       " 639998                            *hangs head* goodnite..\n",
       " 639999  i see lightning outside. i really don't mind i...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 640000    i burnt the top of my mouth and it really hurts\n",
       " 640001  trying out opera mobile 9.7b. it keeps locking...\n",
       " 640002  yeah, i had also pinged. but my net connection...\n",
       " 640003  iâ´m soo bored   the weather is rainy  thereâ´...\n",
       " 640004               @ 'work' more tired than i should be\n",
       " ...                                                   ...\n",
       " 799995                                     gmail is down?\n",
       " 799996                       rest in peace farrah! so sad\n",
       " 799997  sounds like a rival is flagging your ads. not ...\n",
       " 799998  has to resit exams over summer...  wishes he w...\n",
       " 799999                        i love  u guys r the best!!\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 800000  im meeting up with one of my besties tonight! ...\n",
       " 800001  thanks for the twitter add, sunisa! i got to m...\n",
       " 800002  being sick can be really cheap when it hurts t...\n",
       " 800003                     he has that effect on everyone\n",
       " 800004  you can tell him that i just burst out laughin...\n",
       " ...                                                   ...\n",
       " 959995                                  ive noticed ahaha\n",
       " 959996  thank-you for the suggestions, shall certainly...\n",
       " 959997     rosie yor faabulous! if i were 16 again id b u\n",
       " 959998  hey girlie! long time no tweet! how are you? w...\n",
       " 959999  follow me please! i need 11 followers more! wo...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                       text\n",
       " 960000                           such a nice sunny day....\n",
       " 960001      once you go mac .. you never go back !  (via )\n",
       " 960002   i get what i want, yes. thus stepford-ish beha...\n",
       " 960003   nadal vs federer on right now! vamos rafa!!!!!...\n",
       " 960004   two snowmen are standing in a field. one says ...\n",
       " ...                                                    ...\n",
       " 1119995  peace twittizens...enjoy the rest of ur day......\n",
       " 1119996                 yes - i want to lick su-bo's muff!\n",
       " 1119997    yeah  theres not a word to describe him lol xxx\n",
       " 1119998  summer help - hire a teenager - start your sea...\n",
       " 1119999                                            thanks!\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                       text\n",
       " 1120000                      is doing feck all right now !\n",
       " 1120001  hi from athens! i think u should have some pro...\n",
       " 1120002  this is my 2nd time doing it so i am starting ...\n",
       " 1120003  going to visit grandma and family members in h...\n",
       " 1120004  yes, and is something i was wondering about. b...\n",
       " ...                                                    ...\n",
       " 1279995  was a fab party  and the new stuff you've got ...\n",
       " 1279996               making the kittens talk in lolspeak.\n",
       " 1279997  still aching after yestdy's board sesh.. off t...\n",
       " 1279998                      ahaha, i love your [finally!]\n",
       " 1279999  finally, the designing is done... http://msahl...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                       text\n",
       " 1280000  if they're important enough i don't write on t...\n",
       " 1280001                                           i do try\n",
       " 1280002                 bored, lonely, looking for friends\n",
       " 1280003  work was so boring yesterday, i nearly dozed o...\n",
       " 1280004  going to nz? it's been a few years but when in...\n",
       " ...                                                    ...\n",
       " 1439995  had a performance tonight, i nailed my solo  o...\n",
       " 1439996  clearing the juniper bush from my hair after t...\n",
       " 1439997  it seems that you're having so much fun!..  i'...\n",
       " 1439998  hey! we want to see your new hair cut!... and ...\n",
       " 1439999     i, the lowly freshman, will take heed of this.\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                       text\n",
       " 1440000              i love u to!!!  nick j is a sudmuffin\n",
       " 1440001                      hehe blame away  new wip ftw!\n",
       " 1440002                            will be going out soon!\n",
       " 1440003                                                yay\n",
       " 1440004  thank you darlin'!  you're one of a kind!  a s...\n",
       " ...                                                    ...\n",
       " 1599994  just woke up. having no school is the best fee...\n",
       " 1599995  thewdb.com - very cool to hear old walt interv...\n",
       " 1599996  are you ready for your mojo makeover? ask me f...\n",
       " 1599997  happy 38th birthday to my boo of alll time!!! ...\n",
       " 1599998                          happy     charity tuesday\n",
       " \n",
       " [159999 rows x 1 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5054adf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:38:32.616554Z",
     "iopub.status.busy": "2021-12-24T19:38:32.615642Z",
     "iopub.status.idle": "2021-12-24T19:42:30.703040Z",
     "shell.execute_reply": "2021-12-24T19:42:30.703526Z",
     "shell.execute_reply.started": "2021-12-24T18:59:43.672707Z"
    },
    "papermill": {
     "duration": 238.111355,
     "end_time": "2021-12-24T19:42:30.703702",
     "exception": false,
     "start_time": "2021-12-24T19:38:32.592347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[                                                     text\n",
       " 0       [upset, cant, update, facebook, texting, might...\n",
       " 1       [dived, many, time, ball, managed, save, rest,...\n",
       " 2                  [whole, body, feel, itchy, like, fire]\n",
       " 3                              [behaving, mad, cant, see]\n",
       " 4                                           [whole, crew]\n",
       " ...                                                   ...\n",
       " 159995  [wished, could, tell, stop, tweeting, cause, b...\n",
       " 159996  [london, ridiculously, hot, left, short, home,...\n",
       " 159997  [one, day, san, jose, officially, vacation, di...\n",
       " 159998  [kind, right, though, ember, sometimes, butthead]\n",
       " 159999  [know, listenin, bad, habit, earlier, started,...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 160000       [layin, bed, headache, ughhhh, waitin, call]\n",
       " 160001                [funeral, ceremony, gloomy, friday]\n",
       " 160002                         [want, hang, friend, soon]\n",
       " 160003       [want, trade, someone, houston, ticket, one]\n",
       " 160004      [repinging, didnt, prom, didnt, like, friend]\n",
       " ...                                                   ...\n",
       " 319995  [kinda, like, like, straight, men, hot, mallea...\n",
       " 319996  [well, watching, moment, find, favourite, prog...\n",
       " 319997  [finally, get, use, internet, day, internet, w...\n",
       " 319998  [talked, fedex, look, like, slurpee, wont, las...\n",
       " 319999                           [morning, finally, made]\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 320000  [one, ever, gave, jake, credit, read, book, al...\n",
       " 320001  [great, got, virus, wot, need, middle, exam, xxx]\n",
       " 320002         [moving, data, dvds, space, storage, disk]\n",
       " 320003  [missed, ian, take, care, best, luck, anything...\n",
       " 320004  [account, cluttered, much, useless, apps, unin...\n",
       " ...                                                   ...\n",
       " 479995  [aww, always, hated, going, dentist, hope, fee...\n",
       " 479996                 [goood, morning, math, exam, soon]\n",
       " 479997  [poor, little, boy, still, sick, still, pretty...\n",
       " 479998  [lost, seven, point, comment, may, miss, game,...\n",
       " 479999  [still, trying, iphone, forgot, weekend, squar...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 480000                   [studying, greek, history, help]\n",
       " 480001  [gauging, wait, security, san, diego, lindberg...\n",
       " 480002                                     [sucked, golf]\n",
       " 480003  [finished, job, day, typically, sun, finished,...\n",
       " 480004  [good, morning, bayside, lol, saved, bell, mor...\n",
       " ...                                                   ...\n",
       " 639995       [need, tonight, need, unwind, got, one, sad]\n",
       " 639996                                 [internet, workin]\n",
       " 639997                      [thinking, much, cant, sleep]\n",
       " 639998                             [hang, head, goodnite]\n",
       " 639999  [see, lightning, outside, really, dont, mind, ...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 640000                  [burnt, top, mouth, really, hurt]\n",
       " 640001        [trying, opera, mobile, keep, locking, htc]\n",
       " 640002  [yeah, also, pinged, net, connection, made, su...\n",
       " 640003  [soo, bored, weather, rainy, thereâ, sun, alon...\n",
       " 640004                                      [work, tired]\n",
       " ...                                                   ...\n",
       " 799995                                            [gmail]\n",
       " 799996                         [rest, peace, farrah, sad]\n",
       " 799997       [sound, like, rival, flagging, much, though]\n",
       " 799998  [resit, exam, summer, wish, worked, harder, fi...\n",
       " 799999                                  [love, guy, best]\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                      text\n",
       " 800000  [meeting, one, besties, tonight, cant, wait, g...\n",
       " 800001  [thanks, twitter, add, sunisa, got, meet, hin,...\n",
       " 800002  [sick, really, cheap, hurt, much, eat, real, f...\n",
       " 800003                                 [effect, everyone]\n",
       " 800004  [tell, burst, laughing, really, loud, thanks, ...\n",
       " ...                                                   ...\n",
       " 959995                              [ive, noticed, ahaha]\n",
       " 959996  [thankyou, suggestion, shall, certainly, paint...\n",
       " 959997                            [rosie, yor, faabulous]\n",
       " 959998  [hey, girlie, long, time, tweet, wiping, tear,...\n",
       " 959999  [follow, please, need, follower, wossy, book, ...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                       text\n",
       " 960000                                  [nice, sunny, day]\n",
       " 960001                             [mac, never, back, via]\n",
       " 960002   [get, want, yes, thus, stepfordish, behavior, ...\n",
       " 960003                [nadal, federer, right, vamos, rafa]\n",
       " 960004   [two, snowman, standing, field, one, say, funn...\n",
       " ...                                                    ...\n",
       " 1119995  [peace, twittizens, enjoy, rest, day, bout, fl...\n",
       " 1119996                     [yes, want, lick, subos, muff]\n",
       " 1119997                   [yeah, word, describe, lol, xxx]\n",
       " 1119998  [summer, help, hire, teenager, start, search, ...\n",
       " 1119999                                           [thanks]\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                       text\n",
       " 1120000                                      [feck, right]\n",
       " 1120001  [athens, think, proper, greek, food, feta, cho...\n",
       " 1120002             [time, starting, back, beginning, day]\n",
       " 1120003  [going, visit, grandma, family, member, huntin...\n",
       " 1120004  [yes, something, wondering, funny, said, mini,...\n",
       " ...                                                    ...\n",
       " 1279995      [fab, party, new, stuff, youve, got, amazing]\n",
       " 1279996                   [making, kitten, talk, lolspeak]\n",
       " 1279997  [still, aching, yestdys, board, sesh, kilnsey,...\n",
       " 1279998                             [ahaha, love, finally]\n",
       " 1279999  [finally, designing, done, httpmsahluwaliablog...\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                       text\n",
       " 1280000  [theyre, important, enough, dont, write, wall,...\n",
       " 1280001                                              [try]\n",
       " 1280002                   [bored, lonely, looking, friend]\n",
       " 1280003  [work, boring, yesterday, nearly, dozed, hayle...\n",
       " 1280004  [going, year, wanaka, make, sure, look, orient...\n",
       " ...                                                    ...\n",
       " 1439995  [performance, tonight, nailed, solo, one, best...\n",
       " 1439996  [clearing, juniper, bush, hair, workout, favor...\n",
       " 1439997                   [seems, youre, much, fun, happy]\n",
       " 1439998  [hey, want, see, new, hair, cut, dont, like, d...\n",
       " 1439999                      [lowly, freshman, take, heed]\n",
       " \n",
       " [160000 rows x 1 columns],\n",
       "                                                       text\n",
       " 1440000                            [love, nick, sudmuffin]\n",
       " 1440001                 [hehe, blame, away, new, wip, ftw]\n",
       " 1440002                                      [going, soon]\n",
       " 1440003                                              [yay]\n",
       " 1440004  [thank, darlin, youre, one, kind, special, one...\n",
       " ...                                                    ...\n",
       " 1599994                [woke, school, best, feeling, ever]\n",
       " 1599995  [thewdbcom, cool, hear, old, walt, interview, ...\n",
       " 1599996               [ready, mojo, makeover, ask, detail]\n",
       " 1599997  [happy, birthday, boo, alll, time, tupac, amar...\n",
       " 1599998                          [happy, charity, tuesday]\n",
       " \n",
       " [159999 rows x 1 columns]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    dfnew[i]['text']=preprocess_data(dfnew[i]['text'])\n",
    "\n",
    "dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d8ee61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:42:30.751719Z",
     "iopub.status.busy": "2021-12-24T19:42:30.751057Z",
     "iopub.status.idle": "2021-12-24T19:42:31.304942Z",
     "shell.execute_reply": "2021-12-24T19:42:31.304493Z",
     "shell.execute_reply.started": "2021-12-24T19:10:07.088566Z"
    },
    "papermill": {
     "duration": 0.579999,
     "end_time": "2021-12-24T19:42:31.305074",
     "exception": false,
     "start_time": "2021-12-24T19:42:30.725075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                     text\n",
       " 0       [upset, cant, update, facebook, texting, might...\n",
       " 1       [dived, many, time, ball, managed, save, rest,...\n",
       " 2                  [whole, body, feel, itchy, like, fire]\n",
       " 3                              [behaving, mad, cant, see]\n",
       " 6       [hey, long, time, see, yes, rain, bit, bit, lo...\n",
       " ...                                                   ...\n",
       " 159995  [wished, could, tell, stop, tweeting, cause, b...\n",
       " 159996  [london, ridiculously, hot, left, short, home,...\n",
       " 159997  [one, day, san, jose, officially, vacation, di...\n",
       " 159998  [kind, right, though, ember, sometimes, butthead]\n",
       " 159999  [know, listenin, bad, habit, earlier, started,...\n",
       " \n",
       " [142512 rows x 1 columns],\n",
       "                                                      text\n",
       " 160000       [layin, bed, headache, ughhhh, waitin, call]\n",
       " 160001                [funeral, ceremony, gloomy, friday]\n",
       " 160002                         [want, hang, friend, soon]\n",
       " 160003       [want, trade, someone, houston, ticket, one]\n",
       " 160004      [repinging, didnt, prom, didnt, like, friend]\n",
       " ...                                                   ...\n",
       " 319995  [kinda, like, like, straight, men, hot, mallea...\n",
       " 319996  [well, watching, moment, find, favourite, prog...\n",
       " 319997  [finally, get, use, internet, day, internet, w...\n",
       " 319998  [talked, fedex, look, like, slurpee, wont, las...\n",
       " 319999                           [morning, finally, made]\n",
       " \n",
       " [142135 rows x 1 columns],\n",
       "                                                      text\n",
       " 320000  [one, ever, gave, jake, credit, read, book, al...\n",
       " 320001  [great, got, virus, wot, need, middle, exam, xxx]\n",
       " 320002         [moving, data, dvds, space, storage, disk]\n",
       " 320003  [missed, ian, take, care, best, luck, anything...\n",
       " 320004  [account, cluttered, much, useless, apps, unin...\n",
       " ...                                                   ...\n",
       " 479995  [aww, always, hated, going, dentist, hope, fee...\n",
       " 479996                 [goood, morning, math, exam, soon]\n",
       " 479997  [poor, little, boy, still, sick, still, pretty...\n",
       " 479998  [lost, seven, point, comment, may, miss, game,...\n",
       " 479999  [still, trying, iphone, forgot, weekend, squar...\n",
       " \n",
       " [142071 rows x 1 columns],\n",
       "                                                      text\n",
       " 480000                   [studying, greek, history, help]\n",
       " 480001  [gauging, wait, security, san, diego, lindberg...\n",
       " 480003  [finished, job, day, typically, sun, finished,...\n",
       " 480004  [good, morning, bayside, lol, saved, bell, mor...\n",
       " 480005  [darn, final, today, gonna, leave, early, arou...\n",
       " ...                                                   ...\n",
       " 639994    [yeah, man, really, doesnt, feel, like, though]\n",
       " 639995       [need, tonight, need, unwind, got, one, sad]\n",
       " 639997                      [thinking, much, cant, sleep]\n",
       " 639998                             [hang, head, goodnite]\n",
       " 639999  [see, lightning, outside, really, dont, mind, ...\n",
       " \n",
       " [142383 rows x 1 columns],\n",
       "                                                      text\n",
       " 640000                  [burnt, top, mouth, really, hurt]\n",
       " 640001        [trying, opera, mobile, keep, locking, htc]\n",
       " 640002  [yeah, also, pinged, net, connection, made, su...\n",
       " 640003  [soo, bored, weather, rainy, thereâ, sun, alon...\n",
       " 640005             [heard, run, away, slam, door, behind]\n",
       " ...                                                   ...\n",
       " 799994      [sick, spending, day, laying, bed, listening]\n",
       " 799996                         [rest, peace, farrah, sad]\n",
       " 799997       [sound, like, rival, flagging, much, though]\n",
       " 799998  [resit, exam, summer, wish, worked, harder, fi...\n",
       " 799999                                  [love, guy, best]\n",
       " \n",
       " [142365 rows x 1 columns],\n",
       "                                                      text\n",
       " 800000  [meeting, one, besties, tonight, cant, wait, g...\n",
       " 800001  [thanks, twitter, add, sunisa, got, meet, hin,...\n",
       " 800002  [sick, really, cheap, hurt, much, eat, real, f...\n",
       " 800004  [tell, burst, laughing, really, loud, thanks, ...\n",
       " 800005     [thans, response, ihad, already, find, answer]\n",
       " ...                                                   ...\n",
       " 959995                              [ive, noticed, ahaha]\n",
       " 959996  [thankyou, suggestion, shall, certainly, paint...\n",
       " 959997                            [rosie, yor, faabulous]\n",
       " 959998  [hey, girlie, long, time, tweet, wiping, tear,...\n",
       " 959999  [follow, please, need, follower, wossy, book, ...\n",
       " \n",
       " [139675 rows x 1 columns],\n",
       "                                                       text\n",
       " 960000                                  [nice, sunny, day]\n",
       " 960001                             [mac, never, back, via]\n",
       " 960002   [get, want, yes, thus, stepfordish, behavior, ...\n",
       " 960003                [nadal, federer, right, vamos, rafa]\n",
       " 960004   [two, snowman, standing, field, one, say, funn...\n",
       " ...                                                    ...\n",
       " 1119994           [come, back, bbq, fed, watered, content]\n",
       " 1119995  [peace, twittizens, enjoy, rest, day, bout, fl...\n",
       " 1119996                     [yes, want, lick, subos, muff]\n",
       " 1119997                   [yeah, word, describe, lol, xxx]\n",
       " 1119998  [summer, help, hire, teenager, start, search, ...\n",
       " \n",
       " [138688 rows x 1 columns],\n",
       "                                                       text\n",
       " 1120001  [athens, think, proper, greek, food, feta, cho...\n",
       " 1120002             [time, starting, back, beginning, day]\n",
       " 1120003  [going, visit, grandma, family, member, huntin...\n",
       " 1120004  [yes, something, wondering, funny, said, mini,...\n",
       " 1120006                       [resting, home, today, zone]\n",
       " ...                                                    ...\n",
       " 1279995      [fab, party, new, stuff, youve, got, amazing]\n",
       " 1279996                   [making, kitten, talk, lolspeak]\n",
       " 1279997  [still, aching, yestdys, board, sesh, kilnsey,...\n",
       " 1279998                             [ahaha, love, finally]\n",
       " 1279999  [finally, designing, done, httpmsahluwaliablog...\n",
       " \n",
       " [139373 rows x 1 columns],\n",
       "                                                       text\n",
       " 1280000  [theyre, important, enough, dont, write, wall,...\n",
       " 1280002                   [bored, lonely, looking, friend]\n",
       " 1280003  [work, boring, yesterday, nearly, dozed, hayle...\n",
       " 1280004  [going, year, wanaka, make, sure, look, orient...\n",
       " 1280005    [always, wake, smile, knowing, best, yet, come]\n",
       " ...                                                    ...\n",
       " 1439995  [performance, tonight, nailed, solo, one, best...\n",
       " 1439996  [clearing, juniper, bush, hair, workout, favor...\n",
       " 1439997                   [seems, youre, much, fun, happy]\n",
       " 1439998  [hey, want, see, new, hair, cut, dont, like, d...\n",
       " 1439999                      [lowly, freshman, take, heed]\n",
       " \n",
       " [138997 rows x 1 columns],\n",
       "                                                       text\n",
       " 1440000                            [love, nick, sudmuffin]\n",
       " 1440001                 [hehe, blame, away, new, wip, ftw]\n",
       " 1440004  [thank, darlin, youre, one, kind, special, one...\n",
       " 1440005  [choreography, killed, installement, cheetah, ...\n",
       " 1440006  [dont, know, mcfly, twitter, profile, prefer, ...\n",
       " ...                                                    ...\n",
       " 1599994                [woke, school, best, feeling, ever]\n",
       " 1599995  [thewdbcom, cool, hear, old, walt, interview, ...\n",
       " 1599996               [ready, mojo, makeover, ask, detail]\n",
       " 1599997  [happy, birthday, boo, alll, time, tupac, amar...\n",
       " 1599998                          [happy, charity, tuesday]\n",
       " \n",
       " [139351 rows x 1 columns]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x=dfnew[i]\n",
    "    dfnew[i]=x[x['text'].map(len)> 2]\n",
    "dfnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7c108c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:42:31.352727Z",
     "iopub.status.busy": "2021-12-24T19:42:31.352154Z",
     "iopub.status.idle": "2021-12-24T19:42:31.427109Z",
     "shell.execute_reply": "2021-12-24T19:42:31.426531Z",
     "shell.execute_reply.started": "2021-12-24T19:11:48.392313Z"
    },
    "papermill": {
     "duration": 0.099657,
     "end_time": "2021-12-24T19:42:31.427253",
     "exception": false,
     "start_time": "2021-12-24T19:42:31.327596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[dived, many, time, ball, managed, save, rest,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[whole, body, feel, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[behaving, mad, cant, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hey, long, time, see, yes, rain, bit, bit, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407545</th>\n",
       "      <td>[woke, school, best, feeling, ever]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407546</th>\n",
       "      <td>[thewdbcom, cool, hear, old, walt, interview, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407547</th>\n",
       "      <td>[ready, mojo, makeover, ask, detail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407548</th>\n",
       "      <td>[happy, birthday, boo, alll, time, tupac, amar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407549</th>\n",
       "      <td>[happy, charity, tuesday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407550 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "0        [upset, cant, update, facebook, texting, might...\n",
       "1        [dived, many, time, ball, managed, save, rest,...\n",
       "2                   [whole, body, feel, itchy, like, fire]\n",
       "3                               [behaving, mad, cant, see]\n",
       "4        [hey, long, time, see, yes, rain, bit, bit, lo...\n",
       "...                                                    ...\n",
       "1407545                [woke, school, best, feeling, ever]\n",
       "1407546  [thewdbcom, cool, hear, old, walt, interview, ...\n",
       "1407547               [ready, mojo, makeover, ask, detail]\n",
       "1407548  [happy, birthday, boo, alll, time, tupac, amar...\n",
       "1407549                          [happy, charity, tuesday]\n",
       "\n",
       "[1407550 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat(dfnew)\n",
    "df=df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f185614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T19:42:31.477528Z",
     "iopub.status.busy": "2021-12-24T19:42:31.476882Z",
     "iopub.status.idle": "2021-12-24T19:42:37.323206Z",
     "shell.execute_reply": "2021-12-24T19:42:37.323702Z"
    },
    "papermill": {
     "duration": 5.87312,
     "end_time": "2021-12-24T19:42:37.323884",
     "exception": false,
     "start_time": "2021-12-24T19:42:31.450764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('sentiment140dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1815.662937,
   "end_time": "2021-12-24T19:42:39.958721",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-24T19:12:24.295784",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
